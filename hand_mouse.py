# hand_mouse.py
import os, cv2, numpy as np, mediapipe as mp, pyautogui, time

# ===== è¨­å®š =====
CAM_INDEX = 0          # â† camera_test.py ã§æ˜ ã£ãŸç•ªå·ã«
TARGET_FPS = 30
FRAME_W, FRAME_H = 1280, 720  # è»½ãã¦ååˆ†ãªã‚µã‚¤ã‚º

SMOOTH_ALPHA = 0.35    # 0ã€œ1 å¤§ãã„ã»ã©æ»‘ã‚‰ã‹ï¼ˆé…ããªã‚‹ï¼‰
MARGIN = 0.10          # ç”»é¢ã®å¤–å‘¨10%ã‚’ç„¡åŠ¹ã«ã—ã¦æš´ã‚ŒæŠ‘åˆ¶
PINCH_ON = 0.04        # ã‚¯ãƒªãƒƒã‚¯ONã—ãã„å€¤ï¼ˆè¦ªæŒ‡-äººå·®ã—æŒ‡ï¼‰
PINCH_OFF = 0.055      # ã‚¯ãƒªãƒƒã‚¯OFFã—ãã„å€¤ï¼ˆãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹ï¼‰
VEL_CAP = 1600         # 1ç§’ã‚ãŸã‚Šã®æœ€å¤§ç§»å‹•pxï¼ˆæš´èµ°åˆ¶å¾¡ï¼‰

# ===== å‰å‡¦ç† =====
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
pyautogui.FAILSAFE = False
screen_w, screen_h = pyautogui.size()

mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1,
                       min_detection_confidence=0.7,
                       min_tracking_confidence=0.7,
                       model_complexity=1)
draw = mp.solutions.drawing_utils

cap = cv2.VideoCapture(CAM_INDEX)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_W)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_H)
cap.set(cv2.CAP_PROP_FPS, TARGET_FPS)
if not cap.isOpened():
    raise RuntimeError(f"ã‚«ãƒ¡ãƒ© {CAM_INDEX} ã‚’é–‹ã‘ã¾ã›ã‚“ã€‚ç•ªå·ã‚’å¤‰ãˆã¦ãã ã•ã„ã€‚")

# çŠ¶æ…‹
cur_x, cur_y = screen_w//2, screen_h//2
clicking = False
prev_t = time.time()

def clamp01(v): return 0.0 if v < 0 else 1.0 if v > 1 else v

while True:
    ok, frame = cap.read()
    if not ok:
        print("ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—å¤±æ•—")
        break

    frame = cv2.flip(frame, 1)
    h, w = frame.shape[:2]
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    res = hands.process(rgb)

    now = time.time()
    dt = max(1e-3, now - prev_t)  # çµŒéç§’
    prev_t = now

    if res.multi_hand_landmarks:
        lm = res.multi_hand_landmarks[0]
        index_tip = lm.landmark[8]
        thumb_tip = lm.landmark[4]

        # ====== ç”»é¢ä¸­å¤®80%ã«ãƒªãƒãƒƒãƒ—ï¼ˆç«¯ã®æš´ã‚ŒæŠ‘åˆ¶ï¼‰======
        nx = (index_tip.x - MARGIN) / (1 - 2*MARGIN)
        ny = (index_tip.y - MARGIN) / (1 - 2*MARGIN)
        nx, ny = clamp01(nx), clamp01(ny)

        target_x = int(nx * screen_w)
        target_y = int(ny * screen_h)

        # ====== é€Ÿåº¦åˆ¶é™ + æŒ‡æ•°ç§»å‹•å¹³å‡ã§ãƒŒãƒ«ãƒŒãƒ«åŒ– ======
        max_step = int(VEL_CAP * dt)             # ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã§å‹•ã‘ã‚‹æœ€å¤§px
        dx, dy = target_x - cur_x, target_y - cur_y
        if abs(dx) > max_step: dx = np.sign(dx) * max_step
        if abs(dy) > max_step: dy = np.sign(dy) * max_step
        cur_x += int(dx * SMOOTH_ALPHA)
        cur_y += int(dy * SMOOTH_ALPHA)

        pyautogui.moveTo(cur_x, cur_y, duration=0)  # é…å»¶ãªã—

        # ====== ãƒ”ãƒ³ãƒã§ã‚¯ãƒªãƒƒã‚¯ï¼ˆãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹ï¼‰======
        dist = np.hypot(index_tip.x - thumb_tip.x, index_tip.y - thumb_tip.y)
        if (not clicking) and dist < PINCH_ON:
            clicking = True
            pyautogui.click()
            print("ğŸ–±ï¸ click")
        elif clicking and dist > PINCH_OFF:
            clicking = False

        # ====== èµ¤ä¸¸ï¼ˆå¤§ï¼‰ & ç›®å°æç”» ======
        cx, cy = int(index_tip.x * w), int(index_tip.y * h)
        cv2.circle(frame, (cx, cy), 18, (0, 0, 255), thickness=-1)  # â˜…å¤§ãã‚èµ¤ä¸¸
        # éª¨æ ¼ã¯è»½ãï¼ˆé‡ã‘ã‚Œã°æ¬¡è¡Œã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
        draw.draw_landmarks(frame, lm, mp_hands.HAND_CONNECTIONS)

    cv2.putText(frame, "ESC to exit", (10, 26),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (40,40,40), 2)
    cv2.imshow("Hand Mouse", frame)
    if cv2.waitKey(1) & 0xFF == 27:
        break

cap.release()
cv2.destroyAllWindows()
